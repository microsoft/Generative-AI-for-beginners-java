<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df269f529a172a0197ef28460bf1da9f",
  "translation_date": "2025-07-25T11:24:41+00:00",
  "source_file": "04-PracticalSamples/README.md",
  "language_code": "it"
}
-->
# Applicazioni Pratiche & Progetti

## Cosa Imparerai
In questa sezione presenteremo tre applicazioni pratiche che mostrano i modelli di sviluppo dell'AI generativa con Java:
- Creare un Generatore di Storie per Animali domestici multi-modale combinando AI lato client e lato server
- Implementare l'integrazione di modelli AI locali con il demo Foundry Local Spring Boot
- Sviluppare un servizio Model Context Protocol (MCP) con l'esempio del Calcolatore

## Indice

- [Introduzione](../../../04-PracticalSamples)
  - [Demo Foundry Local Spring Boot](../../../04-PracticalSamples)
  - [Generatore di Storie per Animali domestici](../../../04-PracticalSamples)
  - [Servizio MCP Calcolatore (Demo MCP per Principianti)](../../../04-PracticalSamples)
- [Progressione dell'Apprendimento](../../../04-PracticalSamples)
- [Riepilogo](../../../04-PracticalSamples)
- [Prossimi Passi](../../../04-PracticalSamples)

## Introduzione

Questo capitolo presenta **progetti di esempio** che dimostrano i modelli di sviluppo dell'AI generativa con Java. Ogni progetto è completamente funzionale e mostra tecnologie AI specifiche, modelli architetturali e best practice che puoi adattare alle tue applicazioni.

### Demo Foundry Local Spring Boot

Il **[Demo Foundry Local Spring Boot](foundrylocal/README.md)** dimostra come integrare modelli AI locali utilizzando l'**OpenAI Java SDK**. Mostra la connessione al modello **Phi-3.5-mini** in esecuzione su Foundry Local, permettendoti di sviluppare applicazioni AI senza dipendere dai servizi cloud.

### Generatore di Storie per Animali domestici

Il **[Generatore di Storie per Animali domestici](petstory/README.md)** è un'applicazione web Spring Boot coinvolgente che dimostra la **elaborazione AI multi-modale** per generare storie creative sugli animali domestici. Combina capacità AI lato client e lato server utilizzando transformer.js per interazioni AI nel browser e l'OpenAI SDK per l'elaborazione lato server.

### Servizio MCP Calcolatore (Demo MCP per Principianti)

Il **[Servizio MCP Calcolatore](mcp/calculator/README.md)** è una dimostrazione semplice del **Model Context Protocol (MCP)** utilizzando Spring AI. Fornisce un'introduzione accessibile ai concetti MCP, mostrando come creare un server MCP di base che interagisce con i client MCP.

## Progressione dell'Apprendimento

Questi progetti sono progettati per costruire concetti basati sui capitoli precedenti:

1. **Inizia con semplicità**: Parti dal Demo Foundry Local Spring Boot per comprendere l'integrazione AI di base con modelli locali
2. **Aggiungi interattività**: Passa al Generatore di Storie per Animali domestici per l'AI multi-modale e le interazioni web
3. **Apprendi le basi di MCP**: Prova il Servizio MCP Calcolatore per comprendere i fondamenti del Model Context Protocol

## Riepilogo

**Congratulazioni!** Hai completato con successo:

- **Creazione di esperienze AI multi-modali** combinando elaborazione AI lato client e lato server
- **Implementazione dell'integrazione di modelli AI locali** utilizzando framework e SDK Java moderni
- **Sviluppo di servizi Model Context Protocol** dimostrando modelli di integrazione degli strumenti

## Prossimi Passi

[Capitolo 5: AI Generativa Responsabile](../05-ResponsibleGenAI/README.md)

**Disclaimer**:  
Questo documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali incomprensioni o interpretazioni errate derivanti dall'uso di questa traduzione.